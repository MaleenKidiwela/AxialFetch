{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00db5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import utm \n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.geodesic as cgeo\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import pyproj\n",
    "from matplotlib import pyplot as plt, patches\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "from scipy.optimize import lsq_linear\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '/path/to/vsm/VSM')\n",
    "import VSM_forward\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"cartopy\")\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import h5py\n",
    "\n",
    "def read_filter_mmr(file, window_size, polynomial_order):\n",
    "    from scipy.signal import savgol_filter\n",
    "    import pandas as pd\n",
    "    from pyproj import Proj\n",
    "   \n",
    "    outline = pd.read_csv(file, header=None)\n",
    "    x = outline[1]\n",
    "    y = outline[0]\n",
    "      \n",
    "    yhat = savgol_filter(y, window_size, polynomial_order) # window size 21, polynomial order 2\n",
    "    xhat = savgol_filter(x, window_size, polynomial_order)\n",
    "   \n",
    "    x_norm = 419691.465854\n",
    "    y_norm = 5081627.38769\n",
    "   \n",
    "    xhat_utm = [x + x_norm for x in xhat]\n",
    "    yhat_utm = [y + y_norm for y in yhat]\n",
    "      \n",
    "    myProj = Proj(\"+proj=utm +zone=9 +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n",
    "    xhat_lon, yhat_lat = myProj(xhat_utm, yhat_utm, inverse=True)\n",
    "   \n",
    "    return xhat_lon, yhat_lat\n",
    "\n",
    "def utm_to_latlon(x, y, zone_number, zone_letter):\n",
    "    \"\"\"\n",
    "    Convert UTM coordinates to latitude and longitude.\n",
    "    \n",
    "    Parameters:\n",
    "    - x, y: UTM coordinates\n",
    "    - zone_number: UTM zone number\n",
    "    - zone_letter: UTM zone letter\n",
    "\n",
    "    Returns:\n",
    "    - lat, lon: Latitude and longitude\n",
    "    \"\"\"\n",
    "\n",
    "    utm_proj = f'+proj=utm +zone={zone_number} +ellps=WGS84 +units=m +no_defs'\n",
    "    if zone_letter < 'N':\n",
    "        utm_proj += ' +south'\n",
    "    \n",
    "    utm = pyproj.Proj(utm_proj)\n",
    "    wgs84 = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "    \n",
    "    transformer = pyproj.Transformer.from_proj(utm, wgs84)\n",
    "    \n",
    "    lon, lat = transformer.transform(x, y)\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def utm_to_latlon_vec(x_array, y_array, zone_number, zone_letter):\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    for x, y in zip(x_array, y_array):\n",
    "        lat, lon = utm_to_latlon(x, y, zone_number, zone_letter)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(lon)\n",
    "    return longitudes, latitudes\n",
    "\n",
    "def latlon_to_utm(lat, lon, zone_number, zone_letter):\n",
    "    \"\"\"\n",
    "    Convert latitude and longitude to UTM coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - lat, lon: Latitude and longitude\n",
    "    - zone_number: UTM zone number\n",
    "    - zone_letter: UTM zone letter\n",
    "\n",
    "    Returns:\n",
    "    - x, y: UTM coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    utm_proj = f'+proj=utm +zone={zone_number} +ellps=WGS84 +units=m +no_defs'\n",
    "    if zone_letter < 'N':\n",
    "        utm_proj += ' +south'\n",
    "    \n",
    "    utm = pyproj.Proj(utm_proj)\n",
    "    wgs84 = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "    \n",
    "    transformer = pyproj.Transformer.from_proj(wgs84, utm)\n",
    "    \n",
    "    x, y = transformer.transform(lon, lat)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def get_displacement_array(X, Y, patch, m):\n",
    "    _, _, uz = VSM_forward.okada(X, Y, \n",
    "                     patch['xtlc'], patch['ytlc'], patch['dtlc']*-1, \n",
    "                     patch['length'], patch['width'], \n",
    "                     patch['strike'], patch['dip'], \n",
    "                     0.0, 0.0, m, 'R', 0.25)\n",
    "    return uz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5033c",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_x, mmr_y = read_filter_mmr('../data/mmr_2d_outline.csv', 21, 2)\n",
    "\n",
    "bathy = pd.read_csv('../data/GMRTv3_9_20211012topo_cut2.xyz', header = None, \\\n",
    "                    delim_whitespace=True)\n",
    "bathy.columns = ['lon', 'lat', 'z']\n",
    "bathy = bathy.astype('float32')\n",
    "bathy_z = bathy['z'].values.reshape(866,640)\n",
    "bathy_x = bathy['lon'].values.reshape(866,640)\n",
    "bathy_y = bathy['lat'].values.reshape(866,640)\n",
    "\n",
    "# Load mmr point cloud for plotting\n",
    "data = np.loadtxt('../data//axial_amc_top_utm_norm_km_20000.xyz')\n",
    "xm = data[:, 0]\n",
    "ym = data[:, 1]\n",
    "x_norm = 419691.465854\n",
    "y_norm = 5081627.38769\n",
    "xm = [x + x_norm for x in xm]\n",
    "ym = [y + y_norm for y in ym]\n",
    "zm = data[:, 2]\n",
    "zm = [(z - 20000+1500) for z in zm] # normalize z coordinate \n",
    "\n",
    "# load rectangles geometry, also just for plotting later. this was created by model3b_voxel_grid.ipynb\n",
    "with open('modified_rectangles.pkl', 'rb') as f:\n",
    "    rectangles = pickle.load(f)\n",
    "\n",
    "# Read the patches CSV into a DataFrame. This is different from the rectangles because it constains \n",
    "# what the okada function needs (rectangle centers not corners). also created by model_3b_voxel_grid.ipynb\n",
    "df = pd.read_csv('patches.csv')\n",
    "# Convert to a list of dictionaries\n",
    "patches = df.to_dict(orient='records')\n",
    "\n",
    "# Read in deformation data\n",
    "mpr_file = '../data/mpr_2016_2020_utm.txt'\n",
    "auv_file = '../data/auv_2016_2020_utm_er.xyz'\n",
    "\n",
    "column_names = [\"x\", \"y\", \"z_displacement\", \"error\"]\n",
    "\n",
    "mpr = pd.read_csv(mpr_file, delim_whitespace=True, names=column_names)\n",
    "auv = pd.read_csv(auv_file, delim_whitespace=True, names=column_names)\n",
    "auv['error'] = auv['error'].replace(0.02, 0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69694de0",
   "metadata": {},
   "source": [
    "# Joint Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5653b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df = pd.concat([mpr, auv], ignore_index=True)\n",
    "observations = list(zip(observations_df[\"x\"], observations_df[\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = len(df)\n",
    "adjacency_matrix = np.zeros((num_patches, num_patches))\n",
    "def are_adjacent(patch1, patch2):\n",
    "    x_distance = abs(patch1['xtlc'] - patch2['xtlc'])\n",
    "    y_distance = abs(patch1['ytlc'] - patch2['ytlc'])\n",
    "    \n",
    "    buffer = 1e-6\n",
    "    \n",
    "    if (x_distance < patch1['width'] + buffer and y_distance < buffer) or \\\n",
    "       (y_distance < patch1['length'] + buffer and x_distance < buffer):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for i in range(num_patches):\n",
    "    for j in range(i+1, num_patches):  # we only need to check half the matrix\n",
    "        if are_adjacent(df.iloc[i], df.iloc[j]):\n",
    "            adjacency_matrix[i, j] = -1\n",
    "            adjacency_matrix[j, i] = -1\n",
    "\n",
    "for i in range(num_patches):\n",
    "    adjacency_matrix[i, i] = -adjacency_matrix[i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3456f",
   "metadata": {},
   "source": [
    "# Construct the Green's function with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a95375",
   "metadata": {},
   "source": [
    "Start out by weighing the datasets evenly - both contribute equally to the inversion based on their uncertainties and number of data points. The MPR data is weighted heavier based on its uncertainty. \n",
    "\n",
    "\\begin{align*}\n",
    "        \\text{Weight for each AUV point} &: \\frac{1}{0.2} = 5 \\\\\n",
    "        \\text{Weight for each MPR point} &: \\frac{1}{0.01} = 100\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "   \\begin{align*}\n",
    "        \\text{Total AUV weight} &: 5 \\times 1006 = 5030 \\\\\n",
    "        \\text{Total MPR weight} &: 100 \\times 9 = 900\n",
    "    \\end{align*}\n",
    "    \n",
    "\n",
    "  \\begin{align*}\n",
    "        \\text{Scaling factor for AUV} &= \\frac{\\text{Desired total weight for AUV}}{\\text{Original total weight for AUV}} \\\\\n",
    "        &= \\frac{900}{5030} \\approx 0.179\n",
    "    \\end{align*}\n",
    "\n",
    "   \\begin{align*}\n",
    "        \\text{Adjusted weight for each AUV point} &: 5 \\times 0.179 = 0.895 \\\\\n",
    "        \\text{Weight for each MPR point} &: \\text{remains unchanged at } 100\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{For the AUV data} &: 0.895 \\text{ for each data point} \\\\\n",
    "    \\text{For the MPR data} &: 100 \\text{ for each data point}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = len(observations)\n",
    "\n",
    "# Create an empty Green's function matrix\n",
    "G = np.zeros((num_observations, num_patches))\n",
    "\n",
    "# Set weights\n",
    "error_weights = 1 / (observations_df[\"error\"])\n",
    "mpr_error_weight = error_weights[:len(mpr)][0]\n",
    "auv_error_weight = error_weights[len(mpr):len(mpr)+1].values[0]\n",
    "total_mpr_weight = mpr_error_weight * len(mpr)\n",
    "total_auv_weight = auv_error_weight * len(auv)\n",
    "scaling_factor_auv = total_mpr_weight / total_auv_weight\n",
    "\n",
    "error_weights[len(mpr):] *= scaling_factor_auv \n",
    "\n",
    "d = np.array(observations_df[\"z_displacement\"]) * error_weights\n",
    "\n",
    "for j, patch in enumerate(patches):\n",
    "    x_obs_array, y_obs_array = zip(*observations)\n",
    "    _, _, uz_array = VSM_forward.okada(np.array(x_obs_array), np.array(y_obs_array), \n",
    "                           patch['xtlc'], patch['ytlc'], patch['dtlc']*-1, \n",
    "                           patch['length'], patch['width'], \n",
    "                           patch['strike'], patch['dip'], \n",
    "                           0.0, 0.0, 1.0, 'R', 0.25)\n",
    "    G[:, j] = uz_array * error_weights\n",
    "    \n",
    "error_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce8be9",
   "metadata": {},
   "source": [
    "# Find optimal smoothing using L-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = np.logspace(-1, 1, 25)\n",
    "d_original = np.array(observations_df[\"z_displacement\"])\n",
    "\n",
    "model_norms = []\n",
    "weighted_rmses = []\n",
    "converged_lambda_values = []\n",
    "rmses_mpr =[]\n",
    "rmses_auv = []\n",
    "\n",
    "for lambda_smoothing in lambda_values:\n",
    "    G_extended = np.vstack([G, lambda_smoothing * adjacency_matrix])\n",
    "    d_extended = np.hstack([d, np.zeros(num_patches)])\n",
    "    lower_bounds = np.zeros(num_patches)\n",
    "    upper_bounds = np.inf * np.ones(num_patches)\n",
    "    res = lsq_linear(G_extended, d_extended, bounds=(lower_bounds, upper_bounds), lsmr_tol='auto')\n",
    "    m = res.x\n",
    "    if res.success:\n",
    "        converged_lambda_values.append(lambda_smoothing)\n",
    "\n",
    "    else:\n",
    "        print(f\"Solution did not converge for lambda = {lambda_smoothing:.2e}. Message: {res.message}\")\n",
    "    d_syn = np.zeros(num_observations)\n",
    "    x_obs_array, y_obs_array = zip(*observations)\n",
    "    for j, patch in enumerate(patches):\n",
    "        _, _, uz_array = VSM_forward.okada(np.array(x_obs_array), np.array(y_obs_array), \n",
    "                               patch['xtlc'], patch['ytlc'], patch['dtlc']*-1, \n",
    "                               patch['length'], patch['width'], \n",
    "                               patch['strike'], patch['dip'],\n",
    "                               0.0, 0.0, m[j], 'R', 0.25)\n",
    "        d_syn += uz_array\n",
    "    \n",
    "    model_norm = np.linalg.norm(m)\n",
    "    model_norms.append(model_norm)\n",
    "    residuals = d_original - d_syn\n",
    "    residuals_mpr = residuals[:len(mpr)]\n",
    "    residuals_auv = residuals[len(mpr):]\n",
    "\n",
    "    rmse_mpr = np.sqrt(np.mean(residuals_mpr**2))\n",
    "    rmse_auv = np.sqrt(np.mean(residuals_auv**2))\n",
    "    rmses_mpr.append(rmse_mpr)\n",
    "    rmses_auv.append(rmse_auv)\n",
    "    \n",
    "    weights_mpr = error_weights[:len(mpr)]\n",
    "    weighted_rmse_mpr = np.sqrt(np.sum(weights_mpr * residuals_mpr**2) / np.sum(weights_mpr))\n",
    "    \n",
    "    weights_auv = error_weights[len(mpr):]\n",
    "    weighted_rmse_auv = np.sqrt(np.sum(weights_auv * residuals_auv**2) / np.sum(weights_auv))\n",
    "    \n",
    "    normalized_weighted_avg_rmse = (weighted_rmse_mpr * len(mpr) + weighted_rmse_auv * len(observations_df[len(mpr):])) / len(observations_df)\n",
    "    weighted_rmses.append(normalized_weighted_avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9320c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_index = 10\n",
    "\n",
    "optimal_mpr_rmse = rmses_mpr[corner_index]\n",
    "optimal_auv_rmse = rmses_auv[corner_index]\n",
    "optimal_norm = model_norms[corner_index]\n",
    "optimal_lambda = lambda_values[corner_index]\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "fig = plt.figure(figsize=(7,3))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(model_norms, rmses_auv, 'o-')\n",
    "plt.xlabel('Model '+r'$L_2$ norm (roughness)')\n",
    "plt.ylabel('RMSE (m)')\n",
    "plt.title('a. AUV L-curve')\n",
    "\n",
    "num_ticks = 6\n",
    "\n",
    "\n",
    "ax1 = plt.gca()\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(num_ticks))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "plt.scatter([optimal_norm], [optimal_auv_rmse], color='red', s=50, zorder=5)  \n",
    "\n",
    "\n",
    "plt.annotate(f'Optimal smoothing \\n($\\lambda$): {optimal_lambda:.2f}', \n",
    "             (optimal_norm, optimal_auv_rmse),\n",
    "             xytext=(1.05*optimal_norm, 1.07*optimal_auv_rmse), \n",
    "             arrowprops=dict(facecolor='black', arrowstyle='-|>', mutation_scale=30, shrinkB=7),\n",
    "             fontsize=10);\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(model_norms, rmses_mpr, 'o-')\n",
    "plt.xlabel('Model '+r'$L_2$ norm (roughness)')\n",
    "plt.ylabel('RMSE (m)')\n",
    "plt.title('b. MPR L-curve')\n",
    "\n",
    "num_ticks = 6\n",
    "\n",
    "ax2 = plt.gca()\n",
    "ax2.xaxis.set_major_locator(MaxNLocator(num_ticks))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "plt.scatter([optimal_norm], [optimal_mpr_rmse], color='red', s=50, zorder=5)  \n",
    " \n",
    "plt.annotate(f'Optimal smoothing \\n($\\lambda$): {optimal_lambda:.2f}', \n",
    "             (optimal_norm, optimal_mpr_rmse),\n",
    "             xytext=(1.05*optimal_norm, 2*optimal_mpr_rmse), \n",
    "             arrowprops=dict(facecolor='black', arrowstyle='-|>', mutation_scale=30, shrinkB=7),\n",
    "             fontsize=10);\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('L_Curve_2016_2020.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e203171",
   "metadata": {},
   "source": [
    "# Do bounded least squares inversion using optimal smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.zeros((num_observations, num_patches))\n",
    "\n",
    "\n",
    "d = np.array(observations_df[\"z_displacement\"]) * error_weights\n",
    "\n",
    "for j, patch in enumerate(patches):\n",
    "    x_obs_array, y_obs_array = zip(*observations)\n",
    "    _, _, uz_array = VSM_forward.okada(np.array(x_obs_array), np.array(y_obs_array), \n",
    "                           patch['xtlc'], patch['ytlc'], patch['dtlc']*-1, \n",
    "                           patch['length'], patch['width'], \n",
    "                           patch['strike'], patch['dip'], \n",
    "                           0.0, 0.0, 1.0, 'R', 0.25)\n",
    "    G[:, j] = uz_array * error_weights\n",
    "\n",
    "G_extended = np.vstack([G, optimal_lambda * adjacency_matrix])\n",
    "d_extended = np.hstack([d, np.zeros(num_patches)])\n",
    "lower_bounds = np.zeros(num_patches)\n",
    "upper_bounds = np.inf * np.ones(num_patches)\n",
    "\n",
    "res = lsq_linear(G_extended, d_extended, bounds=(lower_bounds, upper_bounds), lsmr_tol='auto')\n",
    "m = res.x\n",
    "\n",
    "dv = [patch['length'] * patch['width'] * slip for patch, slip in zip(patches, m)]\n",
    "dv_tot =  sum(dv)/1e9\n",
    "print(\"Volume change: {:.6f} km\\u00B3\".format(dv_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f5ef16",
   "metadata": {},
   "source": [
    "# Generate gridded synthetic displacements and calculate rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f30cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lon_max, lat_min, lat_max = -130.0908385, -129.831339125, 45.8310127, 46.0402239975\n",
    "\n",
    "x_min, y_min, _, _ = utm.from_latlon(lat_min, lon_min)\n",
    "x_max, y_max, _, _ = utm.from_latlon(lat_max, lon_max)\n",
    "\n",
    "resolution = 20\n",
    "x = np.arange(x_min, x_max + resolution, resolution)\n",
    "y = np.arange(y_min, y_max + resolution, resolution)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.zeros_like(X)\n",
    "for j, patch in enumerate(patches):\n",
    "    Z += get_displacement_array(X, Y, patch, m[j])\n",
    "    \n",
    "# Horizontal displacements\n",
    "UX = np.zeros_like(X)\n",
    "UY = np.zeros_like(X)\n",
    "for j, patch in enumerate(patches):\n",
    "    ux_flat, uy_flat, _ = VSM_forward.okada(\n",
    "        X.ravel(), Y.ravel(),\n",
    "        patch['xtlc'], patch['ytlc'], patch['dtlc'] * -1,\n",
    "        patch['length'], patch['width'],\n",
    "        patch['strike'], patch['dip'],\n",
    "        0.0, 0.0, m[j], 'R', 0.25\n",
    "    )\n",
    "    UX += ux_flat.reshape(X.shape)\n",
    "    UY += uy_flat.reshape(X.shape)\n",
    "\n",
    "d_original = np.array(observations_df[\"z_displacement\"])\n",
    "\n",
    "d_syn = np.zeros(num_observations)\n",
    "x_obs_array, y_obs_array = zip(*observations)\n",
    "\n",
    "for j, patch in enumerate(patches):\n",
    "    _, _, uz_array = VSM_forward.okada(np.array(x_obs_array), np.array(y_obs_array), \n",
    "                           patch['xtlc'], patch['ytlc'], patch['dtlc']*-1, \n",
    "                           patch['length'], patch['width'], \n",
    "                           patch['strike'], patch['dip'],\n",
    "                           0.0, 0.0, m[j], 'R', 0.25)\n",
    "    d_syn += uz_array\n",
    "    \n",
    "\n",
    "residuals = d_original - d_syn\n",
    "combined_weighted_rmse = np.sqrt(np.sum(error_weights * residuals**2) / np.sum(error_weights))\n",
    "print(\"Combined rmse: \"+str(combined_weighted_rmse))\n",
    "\n",
    "residuals_mpr = residuals[:len(mpr)]\n",
    "residuals_auv = residuals[len(mpr):]\n",
    "\n",
    "rmse_mpr = np.sqrt(np.mean(residuals_mpr**2))\n",
    "rmse_auv = np.sqrt(np.mean(residuals_auv**2))\n",
    "\n",
    "print(\"RMSE for mpr:\", rmse_mpr)\n",
    "print(\"RMSE for auv:\", rmse_auv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08836cd7",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad057dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(vmin=min(m), vmax=max(m))\n",
    "colormap = plt.get_cmap('hot_r')\n",
    "\n",
    "zone_number = 9  \n",
    "zone_letter = 'T'  \n",
    "\n",
    "lat, lon = utm_to_latlon(X, Y, zone_number, zone_letter)\n",
    "\n",
    "vmn = -5\n",
    "vmx = 5\n",
    "colornum = 30\n",
    "levels = np.linspace(-2500, 1300, 140) \n",
    "xlim = [-130.067, -129.91]\n",
    "ylim = [45.87, 46.04]\n",
    "cm = 'viridis'\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "fig.suptitle(\"MMR 3D Joint Inversion\", fontsize=24)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "d = plt.contour(bathy_x, bathy_y, bathy_z, levels, transform = ccrs.PlateCarree(),colors='black', \\\n",
    "               linewidths = 1, linestyles='solid', zorder=2, alpha = .6);\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim);\n",
    "\n",
    "ax.set_yticks(np.linspace(ylim[0]+0.02, ylim[1]-0.01, 4), crs = ccrs.PlateCarree())\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.set_xticks(np.linspace(xlim[0]+0.02, xlim[1]-0.015,4), crs = ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "plt.yticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.plot(mmr_x, mmr_y,'--', transform = ccrs.PlateCarree(), color='black', alpha=1, linewidth = 2)\n",
    "\n",
    "for idx, rectangle in enumerate(rectangles):\n",
    "    latlon_rectangle = []\n",
    "    \n",
    "    for vertex in rectangle:\n",
    "        x, y, _ = vertex\n",
    "        latitude, longitude = utm_to_latlon(x, y, zone_number, zone_letter)\n",
    "        latlon_rectangle.append((latitude, longitude))\n",
    "    \n",
    "    latitudes = [point[0] for point in latlon_rectangle]\n",
    "    longitudes = [point[1] for point in latlon_rectangle]\n",
    "    \n",
    "    color = colormap(norm(m[idx]))\n",
    "    polygon = Polygon(list(zip(longitudes, latitudes)), fill=True, facecolor=color, \\\n",
    "                      edgecolor='black', alpha=0.8, linewidth=0.1)\n",
    "    ax.add_patch(polygon)\n",
    "    \n",
    "sm = plt.cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "cb = plt.colorbar(sm, ax=ax)\n",
    "cb.set_label(\"Patch opening (m)\", fontsize=15)\n",
    "\n",
    "plt.title('Patch opening')\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    " \n",
    "c = plt.contourf(lon, lat, Z, colornum, cmap=cm,\\\n",
    "               zorder=1, transform = ccrs.PlateCarree())\n",
    "\n",
    "d = plt.contour(bathy_x, bathy_y, bathy_z, levels, transform = ccrs.PlateCarree(),colors='black', \\\n",
    "               linewidths = 1, linestyles='solid', zorder=2, alpha = .6);\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim);\n",
    "\n",
    "ax.set_yticks(np.linspace(ylim[0]+0.02, ylim[1]-0.01, 4), crs = ccrs.PlateCarree())\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.set_xticks(np.linspace(xlim[0]+0.02, xlim[1]-0.015,4), crs = ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "plt.yticks(rotation=90)\n",
    "\n",
    "mpr_x, mpr_y = zip(*observations[:len(mpr)])\n",
    "mpr_lon, mpr_lat = utm_to_latlon_vec(mpr_x, mpr_y, zone_number, zone_letter)\n",
    "\n",
    "mpr_z_data = np.array(observations_df[\"z_displacement\"][:len(mpr)])\n",
    "mpr_z_synth = d_syn[:len(mpr)]\n",
    "\n",
    "for xi, yi, zi in zip(mpr_lon, mpr_lat, mpr_z_data):\n",
    "    q = plt.quiver(xi, yi, 0, zi, transform=ccrs.PlateCarree(), color='red', scale=7, \n",
    "                   headlength=4, headaxislength=3, width=0.015, \n",
    "                   zorder=4, edgecolor='white', linewidth=0.9)\n",
    "\n",
    "for xi, yi, zi in zip(mpr_lon, mpr_lat, mpr_z_synth):\n",
    "    r = plt.quiver(xi, yi, 0, zi, transform=ccrs.PlateCarree(), color='blue', scale=7, \n",
    "                   headlength=7, headaxislength=6, width=0.009, \n",
    "                   zorder=4, edgecolor='white', linewidth=0.9)\n",
    "\n",
    "plt.plot(mmr_x, mmr_y,'--', transform = ccrs.PlateCarree(), color='yellow', alpha=1)\n",
    "   \n",
    "ax.add_patch(mpatches.Rectangle(xy=[0.68, 0.68],width=0.3,height=0.3,facecolor='white', transform=ax.transAxes, \\\n",
    "                    zorder=3, edgecolor='black', alpha=0.6))\n",
    "qk = plt.quiverkey(q, -129.9475, 46.012, 1, 'Data', angle = 90, coordinates='data', labelpos = 'N', \\\n",
    "                  labelsep=0.55, zorder=4, edgecolor='white', linewidth=1);\n",
    "qk2 = plt.quiverkey(r, -129.926, 46.012, 1, 'Model', angle = 90, coordinates='data', labelpos = 'N', \\\n",
    "                  labelsep=0.55, zorder=4, edgecolor='white', linewidth=1);\n",
    "plt.text(-129.946, 45.993, '1 meter', zorder=4, fontsize = 15);\n",
    "\n",
    "cb = plt.colorbar(c);\n",
    "cb.set_label('Modeled vertical displacement (m)', fontsize=15)\n",
    "ax.add_patch(mpatches.Rectangle(xy=[0.02, 0.02],width=0.48,height=0.12,facecolor='white', transform=ax.transAxes, \\\n",
    "                    zorder=3, edgecolor='black', alpha=0.6))\n",
    "plt.text(-130.06, 45.885, 'MPR rmse: '+str(\"{:.3f}\".format(rmse_mpr))+' m', color='black', fontsize=18);\n",
    "plt.text(-130.06, 45.877, 'AUV rmse: '+str(\"{:.3f}\".format(rmse_auv))+' m', color='black', fontsize=18);\n",
    "\n",
    "plt.title('Modeled displacement')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fea5d",
   "metadata": {},
   "source": [
    "# Read out the model data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b867259",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('model3b_joint_2016_2020.h5', 'w') as hf:\n",
    "    # Save rectangles\n",
    "    hf.create_dataset(\"rectangles\", data=rectangles, dtype='float64')\n",
    "    \n",
    "    # Save m\n",
    "    hf.create_dataset(\"m\", data=m, dtype='float64')\n",
    "    \n",
    "    # Save lat, lon, Z\n",
    "    hf.create_dataset(\"lat\", data=lat, dtype='float64')\n",
    "    hf.create_dataset(\"lon\", data=lon, dtype='float64')\n",
    "    hf.create_dataset(\"Z\", data=Z, dtype='float64')\n",
    "    hf.create_dataset(\"UX\",         data=UX,         dtype='float64')\n",
    "    hf.create_dataset(\"UY\",         data=UY,         dtype='float64')\n",
    "    \n",
    "    # Save synthetic mpr data\n",
    "    hf.create_dataset(\"mpr_lon\", data=mpr_lon, dtype='float64')\n",
    "    hf.create_dataset(\"mpr_lat\", data=mpr_lat, dtype='float64')\n",
    "    hf.create_dataset(\"mpr_z\", data=mpr_z_synth, dtype='float64')\n",
    "    \n",
    "    # Save rmse_auv, rmse_mpr, and dv\n",
    "    hf.attrs['rmse_auv'] = rmse_auv\n",
    "    hf.attrs['rmse_mpr'] = rmse_mpr\n",
    "    hf.attrs['dv'] = dv_tot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
